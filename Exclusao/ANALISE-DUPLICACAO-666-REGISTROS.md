# üîç AN√ÅLISE: Duplica√ß√£o de 666 Registros no import_data

**Data da An√°lise:** 28/09/2025 02:47  
**Investigador:** Barcelitos AI  
**Problema:** Re-entrada de 666 registros na tabela `import_data`

## üìä Dados Identificados

### Jobs Duplicados
```sql
-- Job 1 (Original)
ID: 756c8136-e879-4cca-8935-5e5068ce19c7
Filename: import_1759024867657.csv
Records: 666
Created: 2025-09-28 02:01:09.786777+00
Updated: 2025-09-28 02:01:10.466849+00
Status: completed

-- Job 2 (Duplicado)
ID: 1e31b6a6-de40-4da8-a457-77fb4f1ab733
Filename: import_1759027633897.csv
Records: 666
Created: 2025-09-28 02:47:15.874457+00
Updated: 2025-09-28 02:47:16.59495+00
Status: completed
```

### An√°lise Temporal
- **Intervalo entre jobs:** ~46 minutos
- **Mesmo tenant:** 8d2888f1-64a5-445f-84f5-2614d5160251 (nexsyn)
- **Mesmo usu√°rio:** 1f98885d-b3dd-4404-bf3a-63dd2937d1f6
- **Mesmo n√∫mero de registros:** 666 (suspeito)

## üîç Causa Raiz Identificada

### 1. **Problema na Interface de Importa√ß√£o**
- O componente `ImportingStep.tsx` permite m√∫ltiplas execu√ß√µes da mesma importa√ß√£o
- N√£o h√° verifica√ß√£o se um job j√° foi processado com os mesmos dados
- O usu√°rio pode inadvertidamente executar a importa√ß√£o novamente

### 2. **Aus√™ncia de Preven√ß√£o de Duplica√ß√£o**
- N√£o existe verifica√ß√£o de hash/checksum do arquivo
- N√£o h√° valida√ß√£o se o mesmo conjunto de dados j√° foi importado
- Sistema permite reprocessamento dos mesmos 532 registros originais

### 3. **Logs Evidenciam Reprocessamento**
```
üîç [DEBUG][ImportingStep] Props recebidas: 
Object { selectedRecordsCount: 532, fieldMappingsCount: 16, ... }

[AUDIT] Executando importa√ß√£o - Tenant: nexsyn, User: 1f98885d-b3dd-4404-bf3a-63dd2937d1f6, Records: 532
```

## üéØ Impacto no Sistema

### ‚úÖ Dados Finais Corretos
- Tabela `customers`: apenas 1 registro (correto)
- Verifica√ß√£o de duplicatas funcionou na inser√ß√£o final
- Sistema de unique constraints preveniu duplica√ß√£o real

### ‚ö†Ô∏è Problemas Identificados
- **Performance:** Processamento desnecess√°rio de 666 registros
- **Storage:** Dados duplicados na tabela `import_data`
- **Logs:** Polui√ß√£o com processamento redundante
- **UX:** Usu√°rio pode confundir-se com m√∫ltiplas execu√ß√µes

## üõ†Ô∏è Solu√ß√µes Recomendadas

### 1. **ALTA PRIORIDADE - Preven√ß√£o de Re-importa√ß√£o**
```typescript
// Implementar verifica√ß√£o de job j√° processado
const checkExistingJob = async (fileHash: string, tenantId: string) => {
  const { data } = await supabase
    .from('import_jobs')
    .select('id, status')
    .eq('tenant_id', tenantId)
    .eq('file_hash', fileHash)
    .eq('status', 'completed')
    .limit(1);
    
  return data?.length > 0;
};
```

### 2. **M√âDIA PRIORIDADE - Hash de Arquivo**
```typescript
// Gerar hash do conte√∫do CSV para identifica√ß√£o √∫nica
const generateFileHash = (csvContent: string): string => {
  return crypto.createHash('sha256').update(csvContent).digest('hex');
};
```

### 3. **BAIXA PRIORIDADE - Limpeza de Dados**
```sql
-- Remover dados duplicados da import_data (manter apenas o mais recente)
DELETE FROM import_data 
WHERE job_id = '756c8136-e879-4cca-8935-5e5068ce19c7';

-- Remover job duplicado
DELETE FROM import_jobs 
WHERE id = '756c8136-e879-4cca-8935-5e5068ce19c7';
```

## üîí Medidas Preventivas

### Interface (ImportingStep.tsx)
- [ ] Desabilitar bot√£o de importa√ß√£o ap√≥s execu√ß√£o
- [ ] Mostrar aviso se job similar j√° existe
- [ ] Implementar loading state persistente

### Backend (Edge Functions)
- [ ] Verificar hash de arquivo antes de processar
- [ ] Implementar cache de jobs processados
- [ ] Adicionar timeout para jobs duplicados

### Database
- [ ] Adicionar √≠ndice √∫nico em (tenant_id, file_hash)
- [ ] Implementar trigger para preven√ß√£o de duplicatas
- [ ] Criar view para jobs √∫nicos por tenant

## üìà Monitoramento

### M√©tricas a Acompanhar
- N√∫mero de jobs duplicados por dia
- Tempo m√©dio entre tentativas de re-importa√ß√£o
- Taxa de sucesso vs falha em importa√ß√µes

### Alertas Recomendados
- Job com mesmo hash processado < 1 hora
- Mais de 3 jobs do mesmo usu√°rio em 10 minutos
- Crescimento an√¥malo da tabela import_data

## ‚úÖ Conclus√£o

**Status:** üü° PROBLEMA IDENTIFICADO E CONTIDO  
**Risco:** BAIXO (dados finais corretos)  
**A√ß√£o Imediata:** Implementar preven√ß√£o de re-importa√ß√£o  
**Prazo:** 24 horas

O sistema funcionou corretamente na preven√ß√£o de duplicatas reais na tabela `customers`, mas permite reprocessamento desnecess√°rio que consome recursos e pode confundir usu√°rios.